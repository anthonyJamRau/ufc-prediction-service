{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3788528",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries for web-scraping and saving to CSV file.\n",
    "import requests\n",
    "import bs4\n",
    "import re\n",
    "import csv\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "#Define paths for url folder and scraped files folder\n",
    "url_path = os.getcwd() + '/urls'\n",
    "file_path = os.getcwd() + '/scraped_files'\n",
    "\n",
    "#Creates csv file for scraped data\n",
    "def create_csv_file():\n",
    "    #If file does not exist, create a new CSV file with column headers\n",
    "    if 'ufc_fight_data.csv' not in os.listdir(file_path):\n",
    "        with open(file_path + '/' + 'ufc_fight_data.csv','w',newline='',encoding='UTF8') as ufc_fight_data:\n",
    "            writer = csv.writer(ufc_fight_data)\n",
    "            writer.writerow(['event_name', \n",
    "                             'referee', \n",
    "                             'f_1', \n",
    "                             'f_2', \n",
    "                             'winner', \n",
    "                             'num_rounds', \n",
    "                             'title_fight',\n",
    "                             'weight_class', \n",
    "                             'gender',\n",
    "                             'result', \n",
    "                             'result_details', \n",
    "                             'finish_round', \n",
    "                             'finish_time', \n",
    "                             'fight_url'])\n",
    "        print('New File Created - ufc_fight_data.csv')\n",
    "    else:\n",
    "        print('Scraping to Existing File - ufc_fight_data.csv')\n",
    "\n",
    "#Ensure each url is only scraped once when script is run multiple times\n",
    "def filter_duplicate_urls(fight_urls):\n",
    "    if 'ufc_fight_data.csv' in os.listdir(file_path):\n",
    "        with open(file_path + '/' + 'ufc_fight_data.csv','r') as csv_file:\n",
    "            reader = csv.DictReader(csv_file)\n",
    "            scraped_fight_urls = [row['fight_url'] for row in reader]\n",
    "            \n",
    "            #Removes previously scraped urls from fight_urls\n",
    "            for url in scraped_fight_urls:\n",
    "                if url in fight_urls:\n",
    "                    fight_urls.remove(url)\n",
    "\n",
    "#Scrape referee name\n",
    "def get_referee(overview):\n",
    "    try:\n",
    "        return overview[3].text.split(':')[1]\n",
    "    except:\n",
    "        return 'NULL'\n",
    "\n",
    "#Scrape both fighter names\n",
    "def get_fighters(fight_details,fight_soup):\n",
    "    try:\n",
    "        return fight_details[0].text, fight_details[1].text\n",
    "    except:\n",
    "        return fight_soup.select('a.b-fight-details__person-link')[0].text, fight_soup.select('a.b-fight-details__person-link')[1].text\n",
    "\n",
    "#Scrape name of winner \n",
    "def get_winner(win_lose):\n",
    "    #If there is a winner, set 'winner' to winning fighter. If no winner (e.g. NC, DQ) set 'winner' to NULL\n",
    "    if (win_lose[0].text.strip()=='W') | (win_lose[1].text.strip()=='W'):\n",
    "        if (win_lose[0].text.strip()=='W'):\n",
    "            return f_1\n",
    "        else:\n",
    "            return f_2\n",
    "    else:\n",
    "        return 'NULL'\n",
    "\n",
    "#Checks if fight is title fight\n",
    "def get_title_fight(fight_type):\n",
    "    if 'Title' in fight_type[0].text:\n",
    "        return 'T'\n",
    "    else:\n",
    "        return 'F'\n",
    "\n",
    "#Scrapes weight class of fight\n",
    "def get_weight_class(fight_type):\n",
    "    if 'Light Heavyweight' in fight_type[0].text.strip():\n",
    "        return 'Light Heavyweight'\n",
    "        \n",
    "    elif 'Women' in fight_type[0].text.strip():\n",
    "        return \"Women's \" + re.findall('\\w*weight',fight_type[0].text.strip())[0]\n",
    "        \n",
    "    elif 'Catch Weight' in fight_type[0].text.strip():\n",
    "        return 'Catch Weight'\n",
    "            \n",
    "    elif 'Open Weight' in fight_type[0].text.strip():\n",
    "        return 'Open Weight'\n",
    "            \n",
    "    else:   \n",
    "        try:\n",
    "            return re.findall('\\w*weight',fight_type[0].text.strip())[0]\n",
    "        except: \n",
    "            return 'NULL'\n",
    "\n",
    "#Checks gender of fight \n",
    "def get_gender(fight_type):\n",
    "    if 'Women' in fight_type[0].text:\n",
    "        return 'F'\n",
    "    else:\n",
    "        return 'M'\n",
    "\n",
    "#Scrapes the way the fight ended (e.g. KO, decision, etc.)\n",
    "def get_result(select_result,select_result_details):\n",
    "    if 'Decision' in select_result[0].text.split(':')[1]:\n",
    "        return select_result[0].text.split(':')[1].split()[0], select_result[0].text.split(':')[1].split()[-1]\n",
    "    else:\n",
    "        return select_result[0].text.split(':')[1], select_result_details[1].text.split(':')[-1]\n",
    "\n",
    "#Scrapes details of each UFC fight and appends to file 'ufc_fight_data.csv'\n",
    "def scrape_fights():\n",
    "    \n",
    "    #Get fight URLs from file\n",
    "    if 'fight_urls.csv' in os.listdir(url_path):\n",
    "        with open(url_path + '/' + 'fight_urls.csv','r') as fight_csv:\n",
    "            reader = csv.reader(fight_csv)\n",
    "            fight_urls = [row[0] for row in reader]\n",
    "    else:\n",
    "        print(\"Missing file: fight_urls.csv - try running 'get_urls.get_fight_urls()'\")\n",
    "\n",
    "    filter_duplicate_urls(fight_urls)\n",
    "    \n",
    "    urls_to_scrape = len(fight_urls)\n",
    "    \n",
    "    if urls_to_scrape == 0:\n",
    "        print('Fight data already scraped')\n",
    "        \n",
    "    else:\n",
    "        create_csv_file()\n",
    "\n",
    "        print(f'Scraping {urls_to_scrape} fights...')\n",
    "        urls_scraped = 0\n",
    "    \n",
    "        with open(file_path + '/' + 'ufc_fight_data.csv','a+') as csv_file:\n",
    "            writer = csv.writer(csv_file)\n",
    "        \n",
    "            for url in fight_urls:\n",
    "\n",
    "                fight_url = requests.get(url)\n",
    "                fight_soup = bs4.BeautifulSoup(fight_url.text,'lxml')\n",
    "\n",
    "                #Define key select statements\n",
    "                overview = fight_soup.select('i.b-fight-details__text-item')\n",
    "                select_result = fight_soup.select('i.b-fight-details__text-item_first')\n",
    "                select_result_details = fight_soup.select('p.b-fight-details__text')\n",
    "                fight_details = fight_soup.select('p.b-fight-details__table-text')\n",
    "                fight_type = fight_soup.select('i.b-fight-details__fight-title')\n",
    "                win_lose = fight_soup.select('i.b-fight-details__person-status')\n",
    "\n",
    "                #Scrape fight details\n",
    "                event_name = fight_soup.h2.text\n",
    "                referee = get_referee(overview)\n",
    "                f_1,f_2 = get_fighters(fight_details,fight_soup)\n",
    "                num_rounds = overview[2].text.split(':')[1].strip()[0]\n",
    "                title_fight = get_title_fight(fight_type)\n",
    "                weight_class = get_weight_class(fight_type)\n",
    "                gender = get_gender(fight_type)  \n",
    "                result,result_details = get_result(select_result,select_result_details)\n",
    "                finish_round = overview[0].text.split(':')[1]\n",
    "                finish_time = re.findall('\\d:\\d\\d',overview[1].text)[0]\n",
    "                if (win_lose[0].text.strip()=='W') | (win_lose[1].text.strip()=='W'):\n",
    "                    if (win_lose[0].text.strip()=='W'):\n",
    "                        winner = f_1\n",
    "                    else:\n",
    "                        winner = f_2\n",
    "                else:\n",
    "                    winner = 'NULL'\n",
    "\n",
    "\n",
    "                #Adds row containing scraped fight details to csv file\n",
    "                writer.writerow([event_name.strip(),\n",
    "                                 referee.strip(), \n",
    "                                 f_1.strip(), \n",
    "                                 f_2.strip(), \n",
    "                                 winner.strip(), \n",
    "                                 num_rounds.strip(), \n",
    "                                 title_fight,\n",
    "                                 weight_class, \n",
    "                                 gender,\n",
    "                                 result.strip(), \n",
    "                                 result_details.strip(), \n",
    "                                 finish_round.strip(), \n",
    "                                 finish_time.strip(), \n",
    "                                 url])\n",
    "                \n",
    "                urls_scraped += 1\n",
    "        print(f'{urls_scraped}/{urls_to_scrape} links scraped successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b1d2019",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries for web-scraping and saving to CSV file.\n",
    "import requests\n",
    "import bs4\n",
    "import re\n",
    "import csv\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "#Define paths for url folder and scraped files folder\n",
    "url_path = os.getcwd() + '/urls'\n",
    "file_path = os.getcwd() + '/scraped_files'\n",
    "\n",
    "def scrape_upcoming():\n",
    "    \n",
    "    with open(file_path + '/' + 'ufc_fight_data.csv','a+') as csv_file:\n",
    "        writer = csv.writer(csv_file)\n",
    "\n",
    "        upcoming = pd.read_csv('urls/event_urls.csv',header=None,names = ['events'])\n",
    "        upcoming_event = upcoming['events'][0]\n",
    "        fight_url = requests.get(upcoming_event)\n",
    "        fight_soup = bs4.BeautifulSoup(fight_url.text,'lxml')\n",
    "        event_name = fight_soup.h2.text.strip()\n",
    "        fight_soup = fight_soup.select('p.b-fight-details__table-text')\n",
    "        temp = [ele.get_text().strip() for ele in fight_soup if len(ele.get_text().strip())>0 and ele.get_text().strip() != 'View Matchup']\n",
    "        counter = 3\n",
    "        for ele in temp[::3]:\n",
    "            writer.writerow([\n",
    "                event_name,\n",
    "                'TBA',\n",
    "                temp[counter-3],\n",
    "                temp[counter-2],\n",
    "                'TBA',\n",
    "                'TBA',\n",
    "                'TBA',\n",
    "                temp[counter-1],\n",
    "                'TBA',\n",
    "                'TBA',\n",
    "                'TBA',\n",
    "                'TBA',\n",
    "                'TBA',\n",
    "                upcoming_event\n",
    "            ])\n",
    "            counter = counter + 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1bb674c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "scrape_upcoming()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96398f0f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'temp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mlen\u001b[39m(temp)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'temp' is not defined"
     ]
    }
   ],
   "source": [
    "len(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5da57eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fight_url = requests.get('http://ufcstats.com/event-details/010986ee359fb863')\n",
    "fight_soup = bs4.BeautifulSoup(fight_url.text,'lxml')\n",
    "# fight_soup = fight_soup.select('p.b-fight-details__table-text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c38c00df",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = [ele.get_text().strip() for ele in fight_soup if len(ele.get_text().strip())>0 and ele.get_text().strip() != 'View Matchup']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5a5d9396",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_tag = fight_soup.find('i', class_='b-list__box-item-title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7d708f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date: January 13, 2024\n"
     ]
    }
   ],
   "source": [
    "if date_tag:\n",
    "    # Extract the text content of the next sibling, which is the date\n",
    "    date = date_tag.find_next_sibling(string=True).strip()\n",
    "    print(\"Date:\", date)\n",
    "else:\n",
    "    print(\"Date not found in HTML.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7aa3769b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'temp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m counter \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ele \u001b[38;5;129;01min\u001b[39;00m temp[::\u001b[38;5;241m3\u001b[39m]:\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(temp[counter\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3\u001b[39m], temp[counter\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m], temp[counter\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m      4\u001b[0m     counter \u001b[38;5;241m=\u001b[39m counter \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m3\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'temp' is not defined"
     ]
    }
   ],
   "source": [
    "counter = 3\n",
    "for ele in temp[::3]:\n",
    "    print(temp[counter-3], temp[counter-2], temp[counter-1])\n",
    "    counter = counter + 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0b87987f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the tag containing \"Significant Strikes\"\n",
    "fight_url = requests.get('http://ufcstats.com/fight-details/3fa8ee3fdc04fe36')\n",
    "fight_soup = bs4.BeautifulSoup(fight_url.text,'lxml')\n",
    "significant_strikes_table = fight_soup.find(\"p\", {\"class\": \"b-fight-details__collapse-link_tot\"},string = '\\n        Significant Strikes\\n\\n      ')\n",
    "section_tag = significant_strikes_table.find_next('tbody', class_='b-fight-details__table-body')\n",
    "fight_stats_table2 = section_tag.select('p.b-fight-details__table-text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4ffa927a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p class=\"b-fight-details__collapse-link_tot\" style=\"margin-bottom: 0px;margin-top: 0px;\">\n",
       "        Significant Strikes\n",
       "\n",
       "      </p>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "significant_strikes_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bb972928",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"b-fight-details__table-text\">\n",
       " <a class=\"b-link b-link_style_black\" href=\"http://ufcstats.com/fighter-details/f1fac969a1d70b08\">Leon Edwards </a>\n",
       " </p>,\n",
       " <p class=\"b-fight-details__table-text\">\n",
       " <a class=\"b-link b-link_style_black\" href=\"http://ufcstats.com/fighter-details/dc9572dd6ec74859\">Colby Covington </a>\n",
       " </p>,\n",
       " <p class=\"b-fight-details__table-text\">\n",
       "       57 of 108\n",
       "     </p>,\n",
       " <p class=\"b-fight-details__table-text\">\n",
       "       44 of 126\n",
       "     </p>,\n",
       " <p class=\"b-fight-details__table-text\">\n",
       "       52%\n",
       "     </p>,\n",
       " <p class=\"b-fight-details__table-text\">\n",
       "       34%\n",
       "     </p>,\n",
       " <p class=\"b-fight-details__table-text\">\n",
       "       21 of 62\n",
       "     </p>,\n",
       " <p class=\"b-fight-details__table-text\">\n",
       "       20 of 86\n",
       "     </p>,\n",
       " <p class=\"b-fight-details__table-text\">\n",
       "       14 of 21\n",
       "     </p>,\n",
       " <p class=\"b-fight-details__table-text\">\n",
       "       7 of 12\n",
       "     </p>,\n",
       " <p class=\"b-fight-details__table-text\">\n",
       "       22 of 25\n",
       "     </p>,\n",
       " <p class=\"b-fight-details__table-text\">\n",
       "       17 of 28\n",
       "     </p>,\n",
       " <p class=\"b-fight-details__table-text\">\n",
       "       56 of 107\n",
       "     </p>,\n",
       " <p class=\"b-fight-details__table-text\">\n",
       "       44 of 125\n",
       "     </p>,\n",
       " <p class=\"b-fight-details__table-text\">\n",
       "       0 of 0\n",
       "     </p>,\n",
       " <p class=\"b-fight-details__table-text\">\n",
       "       0 of 1\n",
       "     </p>,\n",
       " <p class=\"b-fight-details__table-text\">\n",
       "       1 of 1\n",
       "     </p>,\n",
       " <p class=\"b-fight-details__table-text\">\n",
       "       0 of 0\n",
       "     </p>]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fight_stats_table2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
